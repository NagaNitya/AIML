{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The NLTK (Natural Language Toolkit) corpus is a collection of text datasets provided by the NLTK library, which is widely used in natural language processing (NLP). These datasets enable developers to experiment with and train NLP models.\n",
    "\n",
    "It includes:\n",
    "- **Text Data**: Collections of books, news articles, chats, etc. (e.g., \"Gutenberg Corpus,\" \"Chat Corpus\").\n",
    "- **Annotated Corpora**: Tagged and structured text, like part-of-speech-tagged sentences (e.g., \"Treebank\").\n",
    "- **Lexical Resources**: Wordlists and dictionaries (e.g., \"WordNet\").\n",
    "- **Language Models**: Pretrained statistical models for tasks like tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nagan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shouldn', 'her', 'all', 'a', 'isn', 'about', \"she's\", 'or', 'she', 'the', 'any', 'further', 'shan', 's', 'him', 'which', 'them', \"we're\", \"haven't\", \"he'll\", 'won', 'nor', 'if', 'how', 'ours', 'yourself', \"don't\", 'he', 'himself', 'can', 'down', \"they've\", 'but', 'd', \"isn't\", \"you'd\", \"i've\", 'its', \"aren't\", 'o', 'whom', 'ourselves', 'we', 'me', 'didn', 'until', 'once', \"it'll\", 'mustn', 'while', 'herself', 'after', \"hadn't\", 'no', 'ma', 'ain', 'other', 'out', \"doesn't\", \"won't\", 'below', 'for', 'had', \"mightn't\", 'that', 'been', 'against', 'hadn', \"they'll\", 'when', \"shan't\", 'by', 'y', \"i'll\", 'itself', 'aren', 'those', 'very', \"you're\", 'an', 'be', 'hers', 'i', 'because', 'few', 'these', 'couldn', \"we'll\", 'do', 'on', \"weren't\", 'has', 'before', 'hasn', 'were', 'only', 'who', 'through', 'not', 'they', 'from', 'wasn', 'did', 't', \"it's\", 'here', \"they'd\", 'it', \"needn't\", \"you'll\", 'doing', 'yours', 'then', \"couldn't\", 'in', 'myself', 'have', 'weren', \"he's\", 'same', 'being', \"hasn't\", 'their', \"i'm\", 'during', 'than', 'under', 'your', 'themselves', \"shouldn't\", \"he'd\", 'was', 'yourselves', 'are', 'don', 'our', 'having', 've', 'too', 'is', \"we've\", \"we'd\", 'over', 'this', 'own', 'you', 'should', 'haven', 'am', 'of', 'and', 'with', \"wouldn't\", \"they're\", 'some', 'll', 'my', 'up', \"wasn't\", 'just', 'between', 'above', 'into', 'more', \"she'll\", 'now', 'theirs', 'where', 'does', 'needn', 'at', \"didn't\", \"it'd\", 'off', 'wouldn', \"she'd\", 'as', 'm', 'such', 'to', 'will', \"mustn't\", 'doesn', 'mightn', \"that'll\", 'why', 'there', \"should've\", 'what', 'most', 'both', \"i'd\", 'his', 're', 'so', \"you've\", 'each', 'again'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sentence=\"This is a sample sentence, showing off the stop words filtration.\"\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'sample', 'sentence', ',', 'showing', 'stop', 'words', 'filtration', '.']\n"
     ]
    }
   ],
   "source": [
    "words=word_tokenize(sentence)\n",
    "filtered_sentence = [w for w in words if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
