{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why use the Keras Functional API?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook we created an MLP model using the Keras Sequential API. This is fine for linear models, but when we want to create models with a non-linear topology or shared layers, we use the functional API instead. the Keras Functional API creates models that are more flexible.\n",
    "\n",
    ">The main idea is that a deep learning model is usually a directed acyclic graph (DAG) of layers. So the functional API is a way to build graphs of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Modules in Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the Keras library there exist multiple modules, which each provide different functionalities and features for the building and training of neural networks. Some of the common modules are discussed below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.models`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can view a model as a way of organising layers into an object. Once we make a model, we can add more training and inference features. \n",
    "\n",
    "The `keras.models` module provides us with different types of models to work with. These are:\n",
    "+ `Sequential`: This is the class we used in the previous notebook, which creates a linear stack of layers.\n",
    "+ `Model`: this class allows us to create more complex architectures, as we will see in further notebooks.\n",
    "+ `load_model`: allows us to load a model that has been saved in a file.\n",
    "+ `save_model`: allows us to save a model to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.layers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Layers are the building blocks of a neural network. The main function of a layer is to take an input, apply a transformation to it, and produce an output.\n",
    "\n",
    "The keras.layers module provides us with many types of layers, that can be combined to create different configurations of neural networks. The main categories of layers are:\n",
    "+ core layers: `Dense`, `Activation`, `Dropout`, `Flatten`, `Reshape`\n",
    "+ convolutional layers: `Conv1D`, `Conv2D`, `Conv3D`, `Conv2DTranspose` \n",
    "+ pooling layers: `MaxPooling1D`, `MaxPooling2D`, `MaxPooling3D`. `AveragePooling1D`, `AveragePooling2D`, `AveragePooling3D`\n",
    "+ recurrent layers: `LSTM`, `RNN`, `GRU`\n",
    "+ normalisation layers: `BatchNormalization`, `LayerNormalization`\n",
    "+ embedding layers: `Embedding`\n",
    "+ advanced activations: `LeakyReLU`. `PReLU`, `ELU`\n",
    "+ merge layers: `Add`, `Subtract`, `Multiply`, `Average`, `Maximum`, `Concatenate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.optimizers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An optimizer in Keras is a method used to update the weights of your neural network to minimize the loss function during training. Optimizers adjust the learning rate and other parameters to improve the model's performance.\n",
    "\n",
    "The `keras.optimizers` module provides optimizer functions that may be implemented in the model.\n",
    "+ `SGD`\n",
    "+ `RMSProp`\n",
    "+ `Adam`\n",
    "+ `Adagrad`\n",
    "+ `Adadelta`\n",
    "+ `Adamax`\n",
    "+ `Nadam`\n",
    "+ `Ftrl`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.callbacks`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras callbacks are special functions that you can use during the training of your machine learning models to customize and extend the behavior of the training process. They allow you to monitor the training process, log information, save models, and even stop training early if certain conditions are met.\n",
    "\n",
    "The `keras.callbacks` module contains various callback functions. These are:\n",
    "+ `ModelCheckpoint`: saves the model after every epoch\n",
    "+ `EarlyStopping`: stops training the model if therer is no improvement by epoch\n",
    "+ `ReduceLROnPlateau`: reduces the learning rate when a model has stopped improving\n",
    "+ `LearningRateScheduler`: changes the learning rate during training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `keras.datasets`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras also offers built in datasets for training models. These are accessed using the `keras.datasets` module. Some of the popular datasets are:\n",
    "+ `mnist`: handwritten digits dataset\n",
    "+ `cifar10`: 60,000 32x32 colour images in 10 classes\n",
    "+ `cifar100`: 60,000 32x32 colour images in 100 classes\n",
    "+ `imdb`: 25,000 movie reviews for binary sentiment classification\n",
    "+ `boston_housing`: Housing prices in Boston"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ [Keras Documentation](https://keras.io/guides/functional_api/)\n",
    "+ github.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
