{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a CNN"
      ],
      "metadata": {
        "id": "QA8Qhu42z9MS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "NBWgBADR1L8c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h3cypElTz7gJ"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras import Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, Input\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prepare the Dataset"
      ],
      "metadata": {
        "id": "poLr6MYMz7Wf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will be making use of the *Cifar-10* dataset, which consists of 32x32 pixel images.\n",
        "\n",
        "Divide the dataset into training and testing sets. Normalise the data into the range (0, 1) by dividing with the highest pixel value (0), then convert to vectors."
      ],
      "metadata": {
        "id": "zx5_uMJT0eZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(trainimage, trainlabel), (testimage, testlabel) = cifar10.load_data()\n",
        "trainimage, testimage=trainimage/255.0, testimage/255.0\n",
        "trainlabelarray=to_categorical(trainlabel, 10)\n",
        "testlabelarray=to_categorical(testlabel, 10)\n",
        "classnames=['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lXKiORPz6ie",
        "outputId": "c3f1c193-d490-4594-a620-f6e162db6d51"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Model"
      ],
      "metadata": {
        "id": "0daLduQd57aF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a model by stacking Conv2D layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "q8Hxb00c6Ddx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def createModel():\n",
        "  input=Input(shape=(32, 32, 3), name='input')\n",
        "  conv1=Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), name='conv1')(input)\n",
        "  pool1=MaxPooling2D(2, 2)(conv1)\n",
        "  drop1=Dropout(0.5)(pool1)\n",
        "  conv2=Conv2D(64, (3, 3), activation='relu', name='conv2')(drop1)\n",
        "  pool2=MaxPooling2D(2, 2)(conv2)\n",
        "  drop2=Dropout(0.5)(pool2)\n",
        "  conv3=Conv2D(128, (3, 3), activation='relu', name='conv3')(drop2)\n",
        "  flat=Flatten()(conv3)\n",
        "  dense1=Dense(128, activation='relu', name='dense1')(flat)\n",
        "  output=Dense(10, activation='softmax', name='output')(dense1)\n",
        "  model=Model(inputs=input, outputs=output)\n",
        "  return model"
      ],
      "metadata": {
        "id": "X08e3b7K3_6E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=createModel()\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "587_3jrYBYSp",
        "outputId": "41b12e0d-4fc5-4278-8da5-5debf7bc6beb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "earlystopping=EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
        "history=model.fit(trainimage, trainlabelarray, epochs=100, shuffle=True, validation_split=0.2, callbacks=[earlystopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPsRdoHyBqaQ",
        "outputId": "e001f72f-83cf-464d-f301-4fcf72ac1b8d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 61ms/step - accuracy: 0.2966 - loss: 1.8860 - val_accuracy: 0.4934 - val_loss: 1.4148\n",
            "Epoch 2/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 58ms/step - accuracy: 0.4998 - loss: 1.3757 - val_accuracy: 0.5457 - val_loss: 1.2807\n",
            "Epoch 3/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.5578 - loss: 1.2286 - val_accuracy: 0.6196 - val_loss: 1.0804\n",
            "Epoch 4/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.5967 - loss: 1.1343 - val_accuracy: 0.6190 - val_loss: 1.0966\n",
            "Epoch 5/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 63ms/step - accuracy: 0.6183 - loss: 1.0814 - val_accuracy: 0.6386 - val_loss: 1.0226\n",
            "Epoch 6/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 74ms/step - accuracy: 0.6311 - loss: 1.0405 - val_accuracy: 0.6695 - val_loss: 0.9493\n",
            "Epoch 7/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 60ms/step - accuracy: 0.6477 - loss: 0.9967 - val_accuracy: 0.6592 - val_loss: 0.9684\n",
            "Epoch 8/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 61ms/step - accuracy: 0.6584 - loss: 0.9692 - val_accuracy: 0.6636 - val_loss: 0.9537\n",
            "Epoch 9/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 57ms/step - accuracy: 0.6726 - loss: 0.9288 - val_accuracy: 0.6777 - val_loss: 0.9211\n",
            "Epoch 10/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 58ms/step - accuracy: 0.6778 - loss: 0.9060 - val_accuracy: 0.6815 - val_loss: 0.8984\n",
            "Epoch 11/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 57ms/step - accuracy: 0.6899 - loss: 0.8772 - val_accuracy: 0.6737 - val_loss: 0.9412\n",
            "Epoch 12/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 58ms/step - accuracy: 0.6962 - loss: 0.8615 - val_accuracy: 0.6865 - val_loss: 0.8919\n",
            "Epoch 13/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 59ms/step - accuracy: 0.7007 - loss: 0.8385 - val_accuracy: 0.6990 - val_loss: 0.8630\n",
            "Epoch 14/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 58ms/step - accuracy: 0.7077 - loss: 0.8260 - val_accuracy: 0.6670 - val_loss: 0.9692\n",
            "Epoch 15/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 59ms/step - accuracy: 0.7120 - loss: 0.8103 - val_accuracy: 0.6859 - val_loss: 0.8974\n",
            "Epoch 16/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 57ms/step - accuracy: 0.7251 - loss: 0.7720 - val_accuracy: 0.6760 - val_loss: 0.9463\n",
            "Epoch 17/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 58ms/step - accuracy: 0.7246 - loss: 0.7738 - val_accuracy: 0.6970 - val_loss: 0.8817\n",
            "Epoch 18/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 58ms/step - accuracy: 0.7248 - loss: 0.7706 - val_accuracy: 0.6813 - val_loss: 0.9056\n",
            "Epoch 19/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 57ms/step - accuracy: 0.7315 - loss: 0.7470 - val_accuracy: 0.6987 - val_loss: 0.8833\n",
            "Epoch 20/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 59ms/step - accuracy: 0.7369 - loss: 0.7429 - val_accuracy: 0.7049 - val_loss: 0.8632\n",
            "Epoch 21/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 57ms/step - accuracy: 0.7488 - loss: 0.7216 - val_accuracy: 0.6777 - val_loss: 0.9519\n",
            "Epoch 22/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 61ms/step - accuracy: 0.7481 - loss: 0.7093 - val_accuracy: 0.7009 - val_loss: 0.8629\n",
            "Epoch 23/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 58ms/step - accuracy: 0.7473 - loss: 0.7080 - val_accuracy: 0.7023 - val_loss: 0.8835\n",
            "Epoch 24/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 58ms/step - accuracy: 0.7556 - loss: 0.6919 - val_accuracy: 0.7083 - val_loss: 0.8690\n",
            "Epoch 25/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 64ms/step - accuracy: 0.7581 - loss: 0.6771 - val_accuracy: 0.7105 - val_loss: 0.8616\n",
            "Epoch 26/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 57ms/step - accuracy: 0.7588 - loss: 0.6707 - val_accuracy: 0.7097 - val_loss: 0.8570\n",
            "Epoch 27/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 59ms/step - accuracy: 0.7614 - loss: 0.6719 - val_accuracy: 0.6974 - val_loss: 0.9057\n",
            "Epoch 28/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 58ms/step - accuracy: 0.7668 - loss: 0.6591 - val_accuracy: 0.7060 - val_loss: 0.8797\n",
            "Epoch 29/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 61ms/step - accuracy: 0.7682 - loss: 0.6506 - val_accuracy: 0.7032 - val_loss: 0.9134\n",
            "Epoch 30/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 60ms/step - accuracy: 0.7720 - loss: 0.6366 - val_accuracy: 0.7032 - val_loss: 0.8817\n",
            "Epoch 31/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 59ms/step - accuracy: 0.7714 - loss: 0.6404 - val_accuracy: 0.6998 - val_loss: 0.9129\n",
            "Epoch 32/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 61ms/step - accuracy: 0.7750 - loss: 0.6299 - val_accuracy: 0.7114 - val_loss: 0.8747\n",
            "Epoch 33/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 58ms/step - accuracy: 0.7786 - loss: 0.6259 - val_accuracy: 0.7080 - val_loss: 0.8675\n",
            "Epoch 34/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 59ms/step - accuracy: 0.7841 - loss: 0.6120 - val_accuracy: 0.7082 - val_loss: 0.8965\n",
            "Epoch 35/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 58ms/step - accuracy: 0.7819 - loss: 0.6128 - val_accuracy: 0.7147 - val_loss: 0.8596\n",
            "Epoch 36/100\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 58ms/step - accuracy: 0.7853 - loss: 0.6021 - val_accuracy: 0.7020 - val_loss: 0.9070\n",
            "Epoch 36: early stopping\n",
            "Restoring model weights from the end of the best epoch: 26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def testModel(model, x, y):\n",
        "  ypred=model.predict(x)\n",
        "  ypred=np.argmax(ypred, axis=1)\n",
        "  print(\"confusion matrix\\n\", confusion_matrix(y, ypred))\n",
        "  print(\"classification report\\n\", classification_report(y, ypred))\n"
      ],
      "metadata": {
        "id": "k3kOs9OvDnq3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testModel(model, testimage, testlabel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQkZkgPSD7a-",
        "outputId": "1f43d430-1cf3-4a49-c291-8eb9693e5714"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step\n",
            "confusion matrix\n",
            " [[736  24  51  14  27   2  13   3 101  29]\n",
            " [ 11 871   4   8   8   5  12   1  32  48]\n",
            " [ 71   7 594  58 127  43  63   6  20  11]\n",
            " [ 22  12  98 517 122 125  54  10  21  19]\n",
            " [ 21   4  87  44 735  18  51  26  10   4]\n",
            " [ 14   3  70 208  79 546  43  17  11   9]\n",
            " [  4   8  48  53  41  14 815   3  11   3]\n",
            " [ 12   3  43  63 134  65  10 638   8  24]\n",
            " [ 54  29  11   9  12   5   4   2 862  12]\n",
            " [ 30 111  18  12  13   5  17   6  51 737]]\n",
            "classification report\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.74      0.75      1000\n",
            "           1       0.81      0.87      0.84      1000\n",
            "           2       0.58      0.59      0.59      1000\n",
            "           3       0.52      0.52      0.52      1000\n",
            "           4       0.57      0.73      0.64      1000\n",
            "           5       0.66      0.55      0.60      1000\n",
            "           6       0.75      0.81      0.78      1000\n",
            "           7       0.90      0.64      0.75      1000\n",
            "           8       0.76      0.86      0.81      1000\n",
            "           9       0.82      0.74      0.78      1000\n",
            "\n",
            "    accuracy                           0.71     10000\n",
            "   macro avg       0.71      0.71      0.70     10000\n",
            "weighted avg       0.71      0.71      0.70     10000\n",
            "\n"
          ]
        }
      ]
    }
  ]
}